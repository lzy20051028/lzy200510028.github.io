---
layout:     post
title:      数据陷阱：认知错误3.1
subtitle:   评价不一致
date:       2020-07-12
author:     刘政永Dmer
header-img: img/post-bg-dmers.jpg
catalog: true
tags:
    - 听取树蛙一篇
---

稍微离题了一小下之后。现在还是回到刚才提及的香蕉。2018年，Ben Jones又做了一个他自认为不太科学的小调查：让他的粉丝根据香蕉的成熟度给10张香蕉照片打分。 每张照片被受访者分为未成熟、几乎成熟、成熟、非常成熟和过熟。 这五种不同的成熟度类别都没有经过全国香蕉评级协会或其他类似机构的审查。所以称之为不太科学的小调查。

![]({{site.baseurl}}/img/post-bg-rz2.jpg)

如上图所示，每张照片展示一次，每个被调查者都以同样的顺序看到了完全相同的香蕉。 当然，人们对香蕉成熟度的看法不会完全一致。比如，一个对我来说熟了的香蕉，对你来说可能是差不多熟了，而对另一个人来说可能会是太熟了。 不过，有点令人吃惊的是，受访者对它们的评价竟如此众说纷纭。在231名受访者中，唯一能看出点一致性的，就是认为十张照片中只有两张照片的成熟度低于另外三张的。余下数据简直一团乱麻，其中四张照片被分为四类，还有一张照片被至少放在五个熟透的组里。结果如下图所示：

![]({{site.baseurl}}/img/post-bg-rz3.jpg)

但这个是此次看似不太靠谱的调查的重点。不知道读者能否意识到一些有意思的东西，在目前如此大的数据结果不一致的表象下，其实埋伏着一些尚不为人知的设计。 提示一下，调查目标不是组间评价者的不一致，而是组内评价者的不一致。好，待我们慢慢看来。

现在注意到Ben Jones所作的把戏了吧?再看一遍照片。这十幅画中有一幅和另一幅完全一样，只是它是另一幅的旋转镜像。 在调查中第二张展示的香蕉的图片在调查结束时再次展示，但它是水平翻转的。 这项调查没有提到这一点，只是简单地要求对每一个成熟度评分。
这个调查的真正“险恶用心”在于，有多少人给这两张照片打分相同，又有多少人打分不同。该调查地假设是10%或者5%的人会改变他们的评级。 事实上，超过三分之一(整整37%)的人改变了他们的评级。在231名受访者中， 有146人对第十张照片的评价和对第二张照片的评价一样，但其中85人对照片的评价不同。

这张桑基图显示了评级者给左边的照片2和右边的照片10打分的变化。

![]({{site.baseurl}}/img/post-bg-rz4.jpg)

从另一种角度来看这种变化，可以察觉导致这种流向的一些线索。 如果我们把被调查者对第二张照片按行打分的方式画出来，把他们对第十张照片按列打分的方式画出来， 我们会注意到，大多数改变评分的人都提高了照片中香蕉的成熟度。

事实上，在85名改变评分的人中，有77人提高了他们的成熟度(例如，从“几乎成熟”到“成熟”，或者从“成熟”到“非常成熟”)， 而只有8人降低了他们的评分。

![]({{site.baseurl}}/img/post-bg-rz5.jpg)

那么，为什么改变评分的评分者中有这么多的人提高了他们的成熟度呢? 这里，让我们看一下第九张的照片。 这些香蕉看起来有点绿，不是吗?是不是意识到什么了。

![]({{site.baseurl}}/img/post-bg-rz6.jpg)

但是,再一次强调,这此调查是非常不科学的和非正式的，完全没有严格的实验控制，仅作启发之用，过于执着于此，则又要跌落陷坑了。 虽然从理论上讲，受访者可能只是随机选择来度过这段时间， 但也很难确定是真的随机。而且受访者没有奖励，所以很难说他们是完全认真对待的。但这个调查中所打开的视角确实是有些参考意义的。
这说明人为的评价，即使在涉及客观对象的时，也会存在巨大的不一致。而且，当有噪声信息进入时，很容易受其影响， 或者产生偏差，或者徒增无意义的看法。可见人们需要对认知过程有一定把握和了解。

那这与当前的香蕉主题有什么关系? 已经提过，每个测量系统都有一定程度的误差，因此需要对测量过程进行重复和再现，以尽量减少偏差；而这不仅适用于给香蕉成熟度评级。 数据是由测量系统创建的，但并不存在完美的测量系统。而且不同的人执行测量过程会得到不同的结果， 即使同一个人重复这个过程，有时也会由于噪声和随机误差的原因而得到不同的读数。那么，这是事实，意味着我们要接受---数据并不能完美地反映现实。 于是引入下一个问题。

本文转载于知乎海数据实验室。